{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4728ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Riccardo Andreoni\n",
    "Title: Implementation of Convolutional Neural Network from scratch.\n",
    "File: utils.py\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class ConvolutionLayer:\n",
    "    def __init__(self, kernel_num, kernel_size):\n",
    "        \"\"\"\n",
    "        Constructor takes as input the number of kernels and their size. I assume only squared filters of size kernel_size x kernel_size\n",
    "        \"\"\"\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_size = kernel_size\n",
    "        # Generate random filters of shape (kernel_num, kernel_size, kernel_size). Divide by kernel_size^2 for weight normalization\n",
    "        self.kernels = np.random.randn(kernel_num, kernel_size, kernel_size) / (kernel_size**2)\n",
    "\n",
    "    def patches_generator(self, image):\n",
    "        \"\"\"\n",
    "        Divide the input image in patches to be used during convolution.\n",
    "        Yields the tuples containing the patches and their coordinates.\n",
    "        \"\"\"\n",
    "        # Extract image height and width\n",
    "        image_h, image_w = image.shape\n",
    "        self.image = image\n",
    "        # The number of patches, given a fxf filter is h-f+1 for height and w-f+1 for width\n",
    "        for h in range(image_h-self.kernel_size+1):\n",
    "            for w in range(image_w-self.kernel_size+1):\n",
    "                patch = image[h:(h+self.kernel_size), w:(w+self.kernel_size)]\n",
    "                yield patch, h, w\n",
    "    \n",
    "    def forward_prop(self, image):\n",
    "        \"\"\"\n",
    "        Perform forward propagation for the convolutional layer.\n",
    "        \"\"\"\n",
    "        # Extract image height and width\n",
    "        image_h, image_w = image.shape\n",
    "        # Initialize the convolution output volume of the correct size\n",
    "        convolution_output = np.zeros((image_h-self.kernel_size+1, image_w-self.kernel_size+1, self.kernel_num))\n",
    "        # Unpack the generator\n",
    "        for patch, h, w in self.patches_generator(image):\n",
    "            # Perform convolution for each patch\n",
    "            convolution_output[h,w] = np.sum(patch*self.kernels, axis=(1,2))\n",
    "        return convolution_output\n",
    "    \n",
    "    def back_prop(self, dE_dY, alpha):\n",
    "        \"\"\"\n",
    "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
    "        to the kernels' weights.\n",
    "        dE_dY comes from the following layer, typically max pooling layer.\n",
    "        It updates the kernels' weights\n",
    "        \"\"\"\n",
    "        # Initialize gradient of the loss function with respect to the kernel weights\n",
    "        dE_dk = np.zeros(self.kernels.shape)\n",
    "        for patch, h, w in self.patches_generator(self.image):\n",
    "            for f in range(self.kernel_num):\n",
    "                dE_dk[f] += patch * dE_dY[h, w, f]\n",
    "        # Update the parameters\n",
    "        self.kernels -= alpha*dE_dk\n",
    "        return dE_dk\n",
    "\n",
    "class MaxPoolingLayer:\n",
    "    def __init__(self, kernel_size):\n",
    "        \"\"\"\n",
    "        Constructor takes as input the size of the kernel\n",
    "        \"\"\"\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def patches_generator(self, image):\n",
    "        \"\"\"\n",
    "        Divide the input image in patches to be used during pooling.\n",
    "        Yields the tuples containing the patches and their coordinates.\n",
    "        \"\"\"\n",
    "        # Compute the ouput size\n",
    "        output_h = image.shape[0] // self.kernel_size\n",
    "        output_w = image.shape[1] // self.kernel_size\n",
    "        self.image = image\n",
    "\n",
    "        for h in range(output_h):\n",
    "            for w in range(output_w):\n",
    "                patch = image[(h*self.kernel_size):(h*self.kernel_size+self.kernel_size), (w*self.kernel_size):(w*self.kernel_size+self.kernel_size)]\n",
    "                yield patch, h, w\n",
    "\n",
    "    def forward_prop(self, image):\n",
    "        image_h, image_w, num_kernels = image.shape\n",
    "        max_pooling_output = np.zeros((image_h//self.kernel_size, image_w//self.kernel_size, num_kernels))\n",
    "        for patch, h, w in self.patches_generator(image):\n",
    "            max_pooling_output[h,w] = np.amax(patch, axis=(0,1))\n",
    "        return max_pooling_output\n",
    "\n",
    "    def back_prop(self, dE_dY):\n",
    "        \"\"\"\n",
    "        Takes the gradient of the loss function with respect to the output and computes the gradients of the loss function with respect\n",
    "        to the kernels' weights.\n",
    "        dE_dY comes from the following layer, typically softmax.\n",
    "        There are no weights to update, but the output is needed to update the weights of the convolutional layer.\n",
    "        \"\"\"\n",
    "        dE_dk = np.zeros(self.image.shape)\n",
    "        for patch,h,w in self.patches_generator(self.image):\n",
    "            image_h, image_w, num_kernels = patch.shape\n",
    "            max_val = np.amax(patch, axis=(0,1))\n",
    "\n",
    "            for idx_h in range(image_h):\n",
    "                for idx_w in range(image_w):\n",
    "                    for idx_k in range(num_kernels):\n",
    "                        if patch[idx_h,idx_w,idx_k] == max_val[idx_k]:\n",
    "                            dE_dk[h*self.kernel_size+idx_h, w*self.kernel_size+idx_w, idx_k] = dE_dY[h,w,idx_k]\n",
    "            return dE_dk\n",
    "\n",
    "class SoftmaxLayer:\n",
    "    \"\"\"\n",
    "    Takes the volume coming from convolutional & pooling layers. It flattens it and it uses it in the next layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_units, output_units):\n",
    "        # Initiallize weights and biases\n",
    "        self.weight = np.random.randn(input_units, output_units)/input_units\n",
    "        self.bias = np.zeros(output_units)\n",
    "\n",
    "    def forward_prop(self, image):\n",
    "        self.original_shape = image.shape # stored for backprop\n",
    "        # Flatten the image\n",
    "        image_flattened = image.flatten()\n",
    "        self.flattened_input = image_flattened # stored for backprop\n",
    "        # Perform matrix multiplication and add bias\n",
    "        first_output = np.dot(image_flattened, self.weight) + self.bias\n",
    "        self.output = first_output\n",
    "        # Apply softmax activation\n",
    "        softmax_output = np.exp(first_output) / np.sum(np.exp(first_output), axis=0)\n",
    "        return softmax_output\n",
    "\n",
    "    def back_prop(self, dE_dY, alpha):\n",
    "        for i, gradient in enumerate(dE_dY):\n",
    "            if gradient == 0:\n",
    "                continue\n",
    "            transformation_eq = np.exp(self.output)\n",
    "            S_total = np.sum(transformation_eq)\n",
    "\n",
    "            # Compute gradients with respect to output (Z)\n",
    "            dY_dZ = -transformation_eq[i]*transformation_eq / (S_total**2)\n",
    "            dY_dZ[i] = transformation_eq[i]*(S_total - transformation_eq[i]) / (S_total**2)\n",
    "\n",
    "            # Compute gradients of output Z with respect to weight, bias, input\n",
    "            dZ_dw = self.flattened_input\n",
    "            dZ_db = 1\n",
    "            dZ_dX = self.weight\n",
    "\n",
    "            # Gradient of loss with respect ot output\n",
    "            dE_dZ = gradient * dY_dZ\n",
    "\n",
    "            # Gradient of loss with respect to weight, bias, input\n",
    "            dE_dw = dZ_dw[np.newaxis].T @ dE_dZ[np.newaxis]\n",
    "            dE_db = dE_dZ * dZ_db\n",
    "            dE_dX = dZ_dX @ dE_dZ\n",
    "\n",
    "            # Update parameters\n",
    "            self.weight -= alpha*dE_dw\n",
    "            self.bias -= alpha*dE_db\n",
    "\n",
    "            return dE_dX.reshape(self.original_shape)\n",
    "\n",
    "def CNN_forward(image, label, layers):\n",
    "    output = image/255.\n",
    "    for layer in layers:\n",
    "        output = layer.forward_prop(output)\n",
    "    # Compute loss (cross-entropy) and accuracy\n",
    "    loss = -np.log(output[label])\n",
    "    accuracy = 1 if np.argmax(output) == label else 0\n",
    "    return output, loss, accuracy\n",
    "\n",
    "def CNN_backprop(gradient, layers, alpha=0.05):\n",
    "    grad_back = gradient\n",
    "    for layer in layers[::-1]:\n",
    "        if type(layer) in [ConvolutionLayer, SoftmaxLayer]:\n",
    "            grad_back = layer.back_prop(grad_back, alpha)\n",
    "        elif type(layer) == MaxPoolingLayer:\n",
    "            grad_back = layer.back_prop(grad_back)\n",
    "    return grad_back\n",
    "\n",
    "\n",
    "def CNN_training(image, label, layers, alpha=0.05):\n",
    "    # Forward step\n",
    "    output, loss, accuracy = CNN_forward(image, label, layers)\n",
    "\n",
    "    # Initial gradient\n",
    "    gradient = np.zeros(10)\n",
    "    gradient[label] = -1/output[label]\n",
    "\n",
    "    # Backprop step\n",
    "    gradient_back = CNN_backprop(gradient, layers, alpha)\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#Test the convolutions with 1 image, to put in the article\n",
    "# Test\n",
    "df_train = pd.read_csv('train.csv')\n",
    "img = df_train.iloc[40,:].values[1:]\n",
    "img = np.reshape(img,(28,28))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "print(img.shape)\n",
    "plt.savefig('images/original_image.png', format='png', dpi=1200)\n",
    "# Test with a convolution of 16 filters of size 3x3\n",
    "my_conv = ConvolutionLayer(32,3)\n",
    "output = my_conv.forward_prop(img)\n",
    "# See the dimensions of the output volume, they follow the usual formula\n",
    "print(output.shape)\n",
    "# Plot 16th volume after the convolution\n",
    "plt.imshow(output[:,:,15], cmap='gray')\n",
    "plt.show()\n",
    "plt.savefig('images/image_convolved.png', format='png', dpi=1200)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
